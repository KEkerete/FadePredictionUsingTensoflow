{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvIJeciM6VeYzWwaENnQZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KEkerete/FadePredictionUsingTensoflow/blob/main/Switching_GRU_Stacked.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YylVCU4B-SGS",
        "outputId": "f3891a3f-ec05-4ba1-e631-ef3d1df50bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time=0.0, rxSite=Chilton, Thresh(dB)=6/14 [0/7,347,893]\n",
            "\n",
            "\n",
            "Time=10000.0, rxSite=Chilton, Thresh(dB)=6/14 [10,000/7,347,893]\n",
            "\n",
            "\n",
            "Time=20000.0, rxSite=Chilton, Thresh(dB)=6/14 [20,000/7,347,893]\n",
            "\n",
            "\n",
            "Time=30000.0, rxSite=Chilton, Thresh(dB)=6/14 [30,000/7,347,893]\n",
            "\n",
            "\n",
            "Time=40000.0, rxSite=Chilton, Thresh(dB)=6/14 [40,000/7,347,893]\n",
            "\n",
            "38/38 [==============================] - 1s 5ms/step\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            "38/38 [==============================] - 1s 5ms/step\n",
            "10/10 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Modifications: Mon Aug 28 00:59:37 2023   @author: keker\n",
        "Modifications: Sun Aug 20 01:15:39 2023   @author: kdellubuntu\n",
        "Created:       Thu Jun 27 20:20:04 2019   @author: ke0015\n",
        "\"\"\"\n",
        "\n",
        "#%%\n",
        "\n",
        "# import sys\n",
        "import warnings\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sys import platform\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.pyplot import figure\n",
        "\n",
        "def debug_signal_handler(signal, frame):  #pause execution with ctl+c, resume with c\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "\n",
        "import signal\n",
        "signal.signal(signal.SIGINT, debug_signal_handler)\n",
        "\n",
        "#%% Define constants\n",
        "min_switching_threshold, max_switching_threshold = 6, 14\n",
        "training_pctge = 0.8\n",
        "predictAheadMins = 5\n",
        "maxMCNdB = 19.57\n",
        "window_sizes = [5, 10, 15]\n",
        "startRow, endRow = 0, 3000000\n",
        "\n",
        "# Define file paths based on platform\n",
        "if platform == 'win32':\n",
        "    BASE_PATH = r'E:\\UniBradford\\Python\\Scripts'\n",
        "else:\n",
        "    BASE_PATH = '/home/kdellubuntu/Python/researchData'\n",
        "\n",
        "#%%\n",
        "# =============================================================================\n",
        "# def preprocess_data(scaler, sequence_length, df):\n",
        "#     scaled_data = scaler.fit_transform(df)\n",
        "#\n",
        "#     X = [scaled_data[i:i + sequence_length] for i in range(len(scaled_data) - sequence_length)]\n",
        "#     y = [scaled_data[i + sequence_length] for i in range(len(scaled_data) - sequence_length)]\n",
        "#\n",
        "#     X, y = np.array(X), np.array(y)\n",
        "#\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "#     return X_train, X_test, y_train, y_test\n",
        "#\n",
        "# def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "#     # model = Sequential([\n",
        "#     #     Bidirectional(GRU(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)),\n",
        "#     #     Dropout(0.2),\n",
        "#     #     GRU(32, return_sequences=False),\n",
        "#     #     Dense(16, activation='relu'),\n",
        "#     #     Dense(1)\n",
        "#     # ])\n",
        "#\n",
        "#     model = Sequential([\n",
        "#         Bidirectional(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)),\n",
        "#         Dropout(0.2),\n",
        "#         GRU(64, return_sequences=False),\n",
        "#         Dense(32, activation='relu'),\n",
        "#         Dense(1)\n",
        "#     ])\n",
        "#\n",
        "#     # model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "#     model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
        "#\n",
        "#     # early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "#     # lr_scheduler = ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-6)\n",
        "#     early_stopping = EarlyStopping(patience=15, restore_best_weights=True)\n",
        "#     lr_scheduler = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=1e-6)\n",
        "#\n",
        "#     # Train the model\n",
        "#     # history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=0)\n",
        "#     history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, lr_scheduler])\n",
        "#\n",
        "#     # Make predictions\n",
        "#     train_predictions = model.predict(X_train)\n",
        "#     test_predictions = model.predict(X_test)\n",
        "#\n",
        "#     # Inverse transform predictions for visualization\n",
        "#     # train_predictions_inv = scaler.inverse_transform(train_predictions)\n",
        "#     # test_predictions_inv = scaler.inverse_transform(test_predictions)\n",
        "#\n",
        "#     # Calculate RMSE\n",
        "#     # train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions_inv))\n",
        "#     # test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions_inv))\n",
        "#\n",
        "#     print(f\"Window Size: {window_size}, Scaler: {scaler.__class__.__name__}\")\n",
        "#     print(f\"Train RMSE: {train_rmse:.4f}\")\n",
        "#     print(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "#     print(\"-----------------------\")\n",
        "#\n",
        "#     #     # # Visualization\n",
        "#     #     # plt.figure(figsize=(12, 6))\n",
        "#     #     # plt.plot(df.index[sequence_length:], df['Edin'][sequence_length:], label='Original Data')\n",
        "#     #     # plt.plot(df.index[sequence_length:sequence_length + len(train_predictions_inv)], train_predictions_inv, label='Train Predictions', linestyle='dashed')\n",
        "#     #     # plt.plot(df.index[sequence_length + len(train_predictions_inv):], test_predictions_inv, label='Test Predictions', linestyle='dashed')\n",
        "#     #     # plt.xlabel('Time (secs)')\n",
        "#     #     # plt.ylabel('Fade (dB)')\n",
        "#     #     # plt.title('Time Series Prediction using Stacked GRU with Attention')\n",
        "#     #     # plt.legend()\n",
        "#     #     # plt.grid(which='major')\n",
        "#     #     # plt.show()\n",
        "#\n",
        "#     # def plot_predictions(data, train_preds, test_preds):\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     plt.plot(data, label='Original Data', color='blue')\n",
        "#     plt.plot(np.arange(window_size, len(train_preds) + window_size), train_preds, label='Train Predictions', color='orange')\n",
        "#     plt.plot(np.arange(len(train_preds) + window_size, len(train_preds) + len(test_preds) + window_size), test_preds, label='Test Predictions', color='green')\n",
        "#     plt.xlabel('Time' (secs))\n",
        "#     plt.ylabel('Fade Scaled Value (dB)')\n",
        "#     plt.title('Original Data vs. Predicted Values')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#     return train_predictions, test_predictions\n",
        "#\n",
        "#\n",
        "# def GRU_Stacked(data):\n",
        "#     df = pd.DataFrame(data)\n",
        "#     window_sizes = [5, 10, 15]\n",
        "#     # scalers = [StandardScaler(), MinMaxScaler()]\n",
        "#     scaler = MinMaxScaler()\n",
        "#     # results = []\n",
        "#\n",
        "#     for window_size in window_sizes:\n",
        "#         # for scaler in scalers:\n",
        "#         X_train, X_test, y_train, y_test = preprocess_data(scaler, window_size, df)\n",
        "#         train_preds, test_preds = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
        "#\n",
        "#         # scaler_name = scaler.__class__.__name__\n",
        "#         # results.append((window_size, scaler_name, train_preds, test_preds))\n",
        "#\n",
        "#\n",
        "#\n",
        "# # Assuming 'original_data' is your original data in scaled form\n",
        "# # original_data = scaled_data[window_size:]\n",
        "# # plot_predictions(data, train_predictions, test_predictions)\n",
        "#\n",
        "#     return train_preds, test_preds  #results\n",
        "# =============================================================================\n",
        "#%%\n",
        "def GRU_Stacked(data):\n",
        "\n",
        "    # near perfect!\n",
        "\n",
        "    # Load dataset\n",
        "    # data = pd.read_csv('/home/kdellubuntu/researchData/TestDataChilEdin.csv')\n",
        "    df = pd.DataFrame(data)   #, index=False, header=False)   # df = data\n",
        "\n",
        "    # Experiment with different window sizes\n",
        "    window_sizes = [5, 10, 15]\n",
        "\n",
        "    for window_size in window_sizes:\n",
        "        # Scaling the data with different scalers\n",
        "        scalers = [StandardScaler(), MinMaxScaler()]\n",
        "\n",
        "        for scaler in scalers:\n",
        "            # Prepare data for training\n",
        "            sequence_length = window_size\n",
        "            X, y = [], []\n",
        "\n",
        "            scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "            for i in range(len(scaled_data) - sequence_length):\n",
        "                X.append(scaled_data[i:i + sequence_length])\n",
        "                y.append(scaled_data[i + sequence_length])\n",
        "            X, y = np.array(X), np.array(y)\n",
        "\n",
        "            # Split data into training and testing sets\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "            # Model architecture\n",
        "            model = Sequential([\n",
        "                Bidirectional(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)),\n",
        "                Dropout(0.2),\n",
        "                GRU(64, return_sequences=False),\n",
        "                Dense(32, activation='relu'),\n",
        "                Dense(1)\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
        "\n",
        "            # Early Stopping and Learning Rate Scheduler\n",
        "            early_stopping = EarlyStopping(patience=15, restore_best_weights=True)\n",
        "            lr_scheduler = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=0)\n",
        "\n",
        "            # Make predictions\n",
        "            train_predictions = model.predict(X_train)\n",
        "            test_predictions = model.predict(X_test)\n",
        "\n",
        "            # Inverse transform predictions for visualization\n",
        "            train_predictions_inv = scaler.inverse_transform(train_predictions)\n",
        "            test_predictions_inv = scaler.inverse_transform(test_predictions)\n",
        "\n",
        "            # Calculate RMSE\n",
        "            # train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions_inv))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions_inv))\n",
        "\n",
        "            # print(f\"Window Size: {window_size}, Scaler: {scaler.__class__.__name__}\")\n",
        "            # print(f\"Train RMSE: {train_rmse:.4f}\")\n",
        "            # print(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "            # print(\"-----------------------\")\n",
        "\n",
        "    # # Visualization\n",
        "    # plt.figure(figsize=(12, 6))\n",
        "    # plt.plot(data, label='Original Data', color='blue')\n",
        "    # # plt.plot(df.index[sequence_length:], df['Edin'][sequence_length:], label='Original Data')\n",
        "    # plt.plot(df.index[sequence_length:sequence_length + len(train_predictions_inv)], train_predictions_inv, label='Train Predictions', linestyle='dashed')\n",
        "    # plt.plot(df.index[sequence_length + len(train_predictions_inv):], test_predictions_inv, label='Test Predictions', linestyle='dashed')\n",
        "    # plt.xlabel('Time (secs)')\n",
        "    # plt.ylabel('Fade (dB)')\n",
        "    # plt.title('Time Series Prediction using Stacked GRU with Attention')\n",
        "    # plt.legend()\n",
        "    # plt.grid(which='major')\n",
        "    # plt.show()\n",
        "\n",
        "    # input('Press any key!')\n",
        "\n",
        "    return train_predictions_inv, test_predictions_inv, test_rmse\n",
        "\n",
        "\n",
        "#%%\n",
        "# def main():\n",
        "start_time = time.time()   #tic\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "# Load data\n",
        "series = read_csv(f'/home/Switching/Data/ChilboltonChiltonFadeData.csv')\n",
        "mod_cod = read_csv(f'/home/Switching/Data/ModCod.csv')\n",
        "\n",
        "total_atten_data = series.values\n",
        "\n",
        "currentSiteCol = 0\n",
        "currentFadeLevelCol = 1\n",
        "currentSpecEffCol = 2\n",
        "wSwitchData = tempSwitchData = [[0, 0, 0.0, 0, '00000000-00000', 0]]\n",
        "specEffData, switchData = [], []\n",
        "predDone = False\n",
        "\n",
        "#%%  Correlation between data\n",
        "# fadeData = series[['Chilbolton','Chilton']]\n",
        "# correlation = fadeData.corr(method='pearson')\n",
        "# print(correlation)\n",
        "# plt.scatter(series.loc[:, 'Chilbolton'], series.loc[:, 'Chilton'])\n",
        "# plt.show()\n",
        "\n",
        "#%% Switching\n",
        "if total_atten_data[0][1] < total_atten_data[0][2]:  # Initial starting site\n",
        "    rxSite = 1  # Chilbolton\n",
        "    altSite = 2\n",
        "else:\n",
        "    rxSite = 2  # Chilton\n",
        "    altSite = 1\n",
        "\n",
        "predictAheadData = predictAheadMins * 60    # seconds\n",
        "trainData = int(predictAheadData * training_pctge / (1 - training_pctge))\n",
        "\n",
        "#%% Loop for dB  minSwitchingThreshold, switchingThreshold\n",
        "for switchingThreshold in range(min_switching_threshold, max_switching_threshold, 2):\n",
        "    sameSiteCount, total_spec_eff, specEffCount = 0, 0, 0\n",
        "\n",
        "    zeroCol = np.zeros((len(total_atten_data), 1))\n",
        "    tData = np.hstack((total_atten_data, zeroCol, zeroCol, zeroCol))\n",
        "    total_atten_data = tData\n",
        "    del tData\n",
        "\n",
        "    currentSiteCol += 3\n",
        "    currentFadeLevelCol += 3\n",
        "    currentSpecEffCol += 3\n",
        "\n",
        "    for k in range(startRow, endRow):  #len(total_atten_data)):\n",
        "        # snrdB = maxMCNdB - total_atten_data[k][rxSite] + 0.5      # snr\n",
        "        # specEffIdx = mod_cod[(mod_cod['SNRdB-upper'] >= snrdB) & (mod_cod['SNRdB-lower'] < snrdB)].values\n",
        "        # specEff = specEffIdx[0][4]\n",
        "        # total_spec_eff += specEff             # total spectral efficiency\n",
        "        sameSiteCount += 1\n",
        "\n",
        "        if k > trainData:\n",
        "            if total_atten_data[k][rxSite] > switchingThreshold:\n",
        "                siteData = total_atten_data[k - trainData : k + predictAheadData,:]\n",
        "                siteData = siteData[:,rxSite]\n",
        "\n",
        "                # quit() ############\n",
        "\n",
        "                # # YPred, cErr = pr.RandForest(siteData)\n",
        "                # # YPred, trngErr, valErr = pr.GRU_Stacked(siteData)\n",
        "                Y_train_pred, Y_test_pred, testRMSE = GRU_Stacked(siteData)\n",
        "                predDone = True\n",
        "                if np.amax(Y_test_pred) > total_atten_data[k][rxSite]:   # check if max(predictedFade) > currentFadeLevel\n",
        "\n",
        "                    altSite = (rxSite % 2) + 1      # Alternate site\n",
        "\n",
        "                if total_atten_data[k][altSite] < total_atten_data[k][rxSite]:   # check if fade(otherSite) < fade(currentSite)\n",
        "                    siteData = total_atten_data[k - trainData : k + predictAheadData,:]\n",
        "                    siteData = siteData[:,altSite]\n",
        "\n",
        "                    # # YPred, cErr = pr.RandForest(siteData)\n",
        "                    # # YPred, trngErr, valErr = pr.GRU_Stacked(siteData)\n",
        "                    Y_train_pred, Y_test_pred, testRMSE  = GRU_Stacked(siteData)\n",
        "                    predDone = True\n",
        "                    # if np.amax(Y_test_pred) > total_atten_data[k][rxSite]:    # check if max(predictedFade) > currentFadeLevel in the altSite\n",
        "                    if np.amax(Y_test_pred) < total_atten_data[k][rxSite]:    # check if max(predictedFade) < currentFadeLevel in the rxSite\n",
        "                        if sameSiteCount >= 60: # must sustain for more than a minute\n",
        "                            tempSwitchData.append([switchingThreshold, rxSite, total_atten_data[k-1][rxSite], sameSiteCount, total_atten_data[k][0], k])\n",
        "                            wSwitchData = np.vstack((wSwitchData, tempSwitchData))\n",
        "                            rxSite = altSite   # Switch to the alternate site\n",
        "                            sameSiteCount = 0  # reset\n",
        "                            tempSwitchData = [[0, 0, 0.0, 0, '00000000-00000', 0]]\n",
        "\n",
        "                            #\n",
        "        if predDone:  # if prediction was done\n",
        "            for i in range(k, k + len(Y_test_pred)):\n",
        "                # do not check the next len(Y_test_pred) samples\n",
        "                # update the next len(Y_test_pred) samples with original data\n",
        "                rxFade = total_atten_data[i][rxSite]\n",
        "                total_atten_data[i, currentSiteCol] = rxSite\n",
        "                total_atten_data[i, currentFadeLevelCol] = rxFade\n",
        "                snrdB = maxMCNdB - total_atten_data[i][rxSite] + 0.5      # snr\n",
        "                specEffIdx = mod_cod[(mod_cod['SNRdB-upper'] >= snrdB) & (mod_cod['SNRdB-lower'] < snrdB)].values\n",
        "                specEff = specEffIdx[0][4]\n",
        "                total_atten_data[i, currentSpecEffCol] = specEff\n",
        "                specEffCount += 1\n",
        "                # total_spec_eff += specEff             # total spectral efficiency\n",
        "\n",
        "            k = min(len(total_atten_data), k + len(Y_test_pred))  # move k pointer\n",
        "            predDone = False\n",
        "\n",
        "        else:\n",
        "            rxFade = total_atten_data[k][rxSite]\n",
        "            total_atten_data[k, currentSiteCol] = rxSite\n",
        "            total_atten_data[k, currentFadeLevelCol] = rxFade\n",
        "            # total_atten_data[k, currentSpecEffCol] = specEff\n",
        "\n",
        "\n",
        "        if k % 10000 == 0:\n",
        "            if rxSite == 1:\n",
        "                siteLoc = \"Chilbolton\"\n",
        "            else:\n",
        "                siteLoc = \"Chilton\"\n",
        "\n",
        "            # print(\"\\nDateTime={}, rxSite={}, Thresh(dB)={:,}/{:,} [{:,}/{:,}]\\n\".format(total_atten_data[k][0].strip(), siteLoc, switchingThreshold, maxSwitchingThreshold, k, len(total_atten_data)))\n",
        "            print(\"\\nTime={}, rxSite={}, Thresh(dB)={:,}/{:,} [{:,}/{:,}]\\n\".format(total_atten_data[k][0], siteLoc, switchingThreshold, max_switching_threshold, k, len(total_atten_data)))\n",
        "\n",
        "\n",
        "    aveSpecEff = total_spec_eff / max(specEffCount, 1)\n",
        "    # len(total_atten_data)\n",
        "    print(\"\\n\\t Average Spectral Efficiency (FER) = {:5.2f}\\n\".format(aveSpecEff))\n",
        "\n",
        "    if len(wSwitchData) > 1:\n",
        "        switchData = wSwitchData[wSwitchData[:, 4] != '00000000-00000']\n",
        "\n",
        "    # input(\"Press any key to continue!\")\n",
        "\n",
        "    #%% Save results\n",
        "\n",
        "    newFadeData = total_atten_data[startRow:endRow,:]  #df.iloc[startRow:endRow]\n",
        "\n",
        "    specEffData.append([switchingThreshold, aveSpecEff])\n",
        "\n",
        "    if platform == 'win32':\n",
        "        SwitchDataFile = r'E:\\UniBradford\\Python\\Scripts\\Results\\SwDataFilePred#'+'{:,}'.format(switchingThreshold)+'mins.csv'\n",
        "        specEffDataFile = r'E:\\UniBradford\\Python\\Scripts\\Results\\SpEffDataFilePred.csv'\n",
        "        newFadeFile = r'E:\\UniBradford\\Python\\Scripts\\Results\\FadeFile.csv'\n",
        "    elif platform == 'linux' or platform == 'linux2':\n",
        "        SwitchDataFile = '/home/Switching/Results/SwDataFilePred#'+'{:,}'.format(switchingThreshold)+'mins.csv'\n",
        "        specEffDataFile = '/home/Switching/Results/SpEffDataFilePred.csv'\n",
        "        newFadeFile = '/home/Switching/Results/FadeFile.csv'\n",
        "\n",
        "    with open(SwitchDataFile, 'w', newline='') as outfile:\n",
        "        csv.writer(outfile).writerows(switchData)\n",
        "\n",
        "    try:\n",
        "        with open(specEffDataFile, 'w', newline='') as outfile:\n",
        "            csv.writer(outfile).writerow(specEffData)\n",
        "    except:\n",
        "        with open(specEffDataFile, 'a', newline='') as outfile:\n",
        "            csv.writer(outfile).writerow(specEffData)\n",
        "\n",
        "    with open(newFadeFile, 'a',  newline='') as outfile:\n",
        "        csv.writer(outfile).writerows(newFadeData)\n",
        "\n",
        "\n",
        "\n",
        "# #%%########################\n",
        "# # input(\"Press any key to cintinue!\")\n",
        "\n",
        "# color_map = plt.get_cmap('tab10')  # You can choose other color maps as well\n",
        "\n",
        "# figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "# plt.title(\"Rain Fades and Switching for Chilbolton and Chilton\", fontsize=14)  #%%s current_date));\n",
        "# # plt.plot([row[1] for row in total_atten_data], \"b\", markersize=10, label=\"rxFade\")  #\n",
        "# # plt.plot([row[0] for row in total_atten_data], \"r\", markersize=10, label=\"Site (1 = Chilbolton, 2 = Edinburgh)\",linewidth=2.0)  # rxSite\n",
        "# plt.plot(total_atten_data[:,1], \"b\", markersize=10, label=\"Chilbolton\")  #\n",
        "# plt.plot(total_atten_data[:,2], \"r\", markersize=10, label=\"Chilton\")  #\n",
        "\n",
        "# j = 3\n",
        "# for idx in range(min_switching_threshold, max_switching_threshold, 2):\n",
        "#     color = color_map(idx)\n",
        "#     plt.plot(2*j + total_atten_data[:,j], color=color, markersize=10, label=f'{idx} dB')  #\n",
        "#     j=j+3\n",
        "\n",
        "# plt.xlim(0, 2000000)  # len(total_atten_data))\n",
        "# plt.legend(loc=\"best\")\n",
        "# plt.xlabel(\"Time (seconds)\")\n",
        "# plt.ylabel(\"Rain fade (dB)\")\n",
        "# plt.grid(which='major')\n",
        "# plt.show()\n",
        "\n",
        "elapsed_time = time.time() - start_time   #toc\n",
        "print('\\n\\n ============================================ \\n\\n')\n",
        "print(\"elapsedTime : {:9.9f} s\".format(elapsed_time))\n",
        "print('\\n ..-Fin!-..\\n')\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    }
  ]
}