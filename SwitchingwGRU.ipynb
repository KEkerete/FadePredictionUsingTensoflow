{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNglooOeKJowP5JIzlqK1jY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KEkerete/FadePredictionUsingTensoflow/blob/main/SwitchingwGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viF2Wrwao2cA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "464deb29-aa1a-4a05-e8c8-1a02ad5cc6e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1450bbba63ca>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dill'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Aug 20 01:15:39 2023\n",
        "\n",
        "@author: kdellubuntu\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jun 27 20:20:04 2019\n",
        "\n",
        "@author: ke0015\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.modules[__name__].__dict__.clear()\n",
        "\n",
        "#%reset -f\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import dill\n",
        "import csv\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "from sys import platform\n",
        "from pandas import read_csv\n",
        "import GRU_Stacked2 as pr  #RandForest as pr\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "def debug_signal_handler(signal, frame):  #pause execution with ctl+c, resume with c\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "import signal\n",
        "signal.signal(signal.SIGINT, debug_signal_handler)\n",
        "\n",
        "#%% -init-\n",
        "maxMCNdB = 19.57        # maximum for ModCod\n",
        "totalSpecEff = 0\n",
        "\n",
        "trainingPctge = 0.8     # Training percentage\n",
        "\n",
        "specEffData = []  #siteIdxNFade, , []\n",
        "wSwitchData = tempSwitchData = [[0, 0, 0.0, 0, '00000000-00000', 0]]\n",
        "\n",
        "predictAheadMins = 5\n",
        "minSwitchingThreshold, maxSwitchingThreshold = 12, 14 # dB\n",
        "currentSiteCol = 1\n",
        "currentFadeLevelCol = 2\n",
        "\n",
        "#%% load dataset\n",
        "# series = read_csv('/home/kdellubuntu/Python/MayJul17Cured.csv')\n",
        "series = read_csv('/home/kdellubuntu/Python/researchData/ChilboltonChiltonFadeData.csv')\n",
        "ModCod = read_csv('/home/kdellubuntu/Python/researchData/ModCod.csv')\n",
        "\n",
        "# csv_file_data = pd.read_csv('/home/kdellubuntu/Python/MetNFadeDataChilbolton.csv')\n",
        "# # csv_filename = pd.read_csv('/home/kdellubuntu/Python/TestDataChilEdin.csv')\n",
        "# input_feature = csv_file_data[['y']]\n",
        "\n",
        "totalAttenData = series.values\n",
        "\n",
        "#%%  Correlation between data\n",
        "# fadeData = series[['Chilbolton','Chilton']]\n",
        "# correlation = fadeData.corr(method='pearson')\n",
        "# print(correlation)\n",
        "# plt.scatter(series.loc[:, 'Chilbolton'], series.loc[:, 'Chilton'])\n",
        "# plt.show()\n",
        "\n",
        "#%% Switching\n",
        "if totalAttenData[0][1] < totalAttenData[0][2]:  # Initial starting site\n",
        "    rxSite = 1  # Chilbolton\n",
        "    altSite = 2\n",
        "else:\n",
        "    rxSite = 2  # Chilton\n",
        "    altSite = 1\n",
        "\n",
        "predictAheadData = predictAheadMins * 60    # seconds\n",
        "trainData = int(predictAheadData * trainingPctge / (1 - trainingPctge))\n",
        "\n",
        "#%% Loop for dB  minSwitchingThreshold, switchingThreshold\n",
        "for switchingThreshold in range(minSwitchingThreshold, maxSwitchingThreshold, 2):\n",
        "    sameSiteCount, totalSpecEff = 0, 0\n",
        "\n",
        "    zeroCol = np.zeros((len(totalAttenData), 1))\n",
        "    tData = np.hstack((totalAttenData, zeroCol, zeroCol))\n",
        "    totalAttenData = tData\n",
        "    del tData\n",
        "\n",
        "    currentSiteCol += 2\n",
        "    currentFadeLevelCol += 2\n",
        "\n",
        "    for k in range(0, len(totalAttenData)):\n",
        "        snrdB = maxMCNdB - totalAttenData[k][rxSite] + 0.5      # snr\n",
        "        specEffIdx = ModCod[(ModCod['SNRdB-upper'] >= snrdB) & (ModCod['SNRdB-lower'] < snrdB)].values\n",
        "        specEff = specEffIdx[0][4]\n",
        "        totalSpecEff += specEff             # total spectral efficiency\n",
        "        sameSiteCount += 1\n",
        "\n",
        "        if k > trainData:\n",
        "            if totalAttenData[k][rxSite] > switchingThreshold:\n",
        "                siteData = totalAttenData[k - trainData : k + predictAheadData,:]\n",
        "                siteData = siteData[:,rxSite]\n",
        "\n",
        "                #save workspace\n",
        "                dill.dump_session('globalsave.pkl')\n",
        "\n",
        "                # quit() ############\n",
        "\n",
        "                # YPred, cErr = pr.RandForest(siteData)\n",
        "                # YPred, trngErr, valErr = pr.GRU_Stacked(siteData)\n",
        "                YPred = pr.GRU_Stacked2(siteData)\n",
        "                if np.amax(YPred) > totalAttenData[k][rxSite]:   # check if max(predictedFade) > currentFadeLevel\n",
        "\n",
        "                    # print(\"rxSite : {:6.3f}\".format(rxSite))\n",
        "                    altSite = (rxSite % 2) + 1      # Alternate site\n",
        "                    # print(\"altSite : {:6.3f}\".format(altSite))\n",
        "                    # input(\"Press any key!\")\n",
        "\n",
        "                if totalAttenData[k][altSite] < totalAttenData[k][rxSite]:   # check if fade(otherSite) < fade(currentSite)\n",
        "                    siteData = totalAttenData[k - trainData : k + predictAheadData,:]\n",
        "                    siteData = siteData[:,rxSite]\n",
        "\n",
        "                    #save workspace\n",
        "                    dill.dump_session('globalsave.pkl')\n",
        "\n",
        "                    # YPred, cErr = pr.RandForest(siteData)\n",
        "                    # YPred, trngErr, valErr = pr.GRU_Stacked(siteData)\n",
        "                    YPred = pr.GRU_Stacked2(siteData)\n",
        "                    if np.amax(YPred) > totalAttenData[k][rxSite]:    # check if max(predictedFade) > currentFadeLevel in the alt site\n",
        "                        if sameSiteCount >= 60: # must sustain for more than a minute\n",
        "                            tempSwitchData.append([switchingThreshold, rxSite, totalAttenData[k-1][rxSite], sameSiteCount, totalAttenData[k][0], k])\n",
        "                            wSwitchData = np.vstack((wSwitchData, tempSwitchData))\n",
        "                            rxSite = altSite   # Switch to the alternate site\n",
        "\n",
        "                        sameSiteCount = 0  # reset\n",
        "                        tempSwitchData = [[0, 0, 0.0, 0, '00000000-00000', 0]]\n",
        "\n",
        "        rxFade = totalAttenData[k][rxSite]\n",
        "        totalAttenData[k, currentSiteCol] = rxSite\n",
        "        totalAttenData[k, currentFadeLevelCol] = rxFade\n",
        "\n",
        "\n",
        "        if k % 10000 == 0:\n",
        "            if rxSite == 1:\n",
        "                siteLoc = \"Chilbolton\"\n",
        "            else:\n",
        "                siteLoc = \"Chilton\"\n",
        "\n",
        "            # print(\"\\nDateTime={}, rxSite={}, Thresh(dB)={:,}/{:,} [{:,}/{:,}]\\n\".format(totalAttenData[k][0].strip(), siteLoc, switchingThreshold, maxSwitchingThreshold, k, len(totalAttenData)))\n",
        "            print(\"\\nTime={}, rxSite={}, Thresh(dB)={:,}/{:,} [{:,}/{:,}]\\n\".format(totalAttenData[k][0], siteLoc, switchingThreshold, maxSwitchingThreshold, k, len(totalAttenData)))\n",
        "\n",
        "\n",
        "    aveSpecEff = totalSpecEff / len(totalAttenData)\n",
        "    print(\"\\n\\t Average Spectral Efficiency (FER) = {:5.2f}\\n\".format(aveSpecEff))\n",
        "\n",
        "    switchData = wSwitchData[wSwitchData[:, 4] != '00000000-00000']\n",
        "\n",
        "    # input(\"Press any key to cintinue!\")\n",
        "\n",
        "    #%% Save results\n",
        "    specEffData.append([switchingThreshold, aveSpecEff])\n",
        "\n",
        "    if platform == 'win32':\n",
        "        SwitchDataFile = \"S:\\Research\\AlphasatData\\Results\\SwDataFilePred2#\"+\"{:,}\".format(switchingThreshold)+\"mins.csv\"\n",
        "        specEffDataFile = \"S:\\Research\\AlphasatData\\Results\\SpEffDataFilePred2.csv\"\n",
        "    elif platform == 'linux' or platform == 'linux2':\n",
        "        SwitchDataFile = \"/home/kdellubuntu/Python/Results/SwDataFilePred2#\"+\"{:,}\".format(switchingThreshold)+\"mins.csv\"\n",
        "        specEffDataFile = \"/home/kdellubuntu/Python/Results/SpEffDataFilePred2.csv\"\n",
        "\n",
        "    with open(SwitchDataFile, 'w', newline='') as outfile:\n",
        "        csv.writer(outfile).writerows(switchData)\n",
        "\n",
        "    try:\n",
        "        with open(specEffDataFile, 'w', newline='') as outfile:\n",
        "            csv.writer(outfile).writerow(specEffData)\n",
        "    except:\n",
        "        with open(specEffDataFile, 'a', newline='') as outfile:\n",
        "            csv.writer(outfile).writerow(specEffData)\n",
        "\n",
        "#%%########################\n",
        "# input(\"Press any key to cintinue!\")\n",
        "\n",
        "color_map = plt.get_cmap('tab10')  # You can choose other color maps as well\n",
        "\n",
        "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title(\"Rain Fades and Switching for Chilbolton and Chilton\", fontsize=14)  #%%s current_date));\n",
        "# plt.plot([row[1] for row in totalAttenData], \"b\", markersize=10, label=\"rxFade\")  #\n",
        "# plt.plot([row[0] for row in totalAttenData], \"r\", markersize=10, label=\"Site (1 = Chilbolton, 2 = Edinburgh)\",linewidth=2.0)  # rxSite\n",
        "plt.plot(totalAttenData[:,1], \"r\", markersize=10, label=\"Chilbolton\")  #\n",
        "plt.plot(totalAttenData[:,2], \"b\", markersize=10, label=\"Chilton\")  #\n",
        "\n",
        "j = 3\n",
        "for idx in range(minSwitchingThreshold, maxSwitchingThreshold, 2 ):\n",
        "    color = color_map(idx)\n",
        "    plt.plot(2*j + totalAttenData[:,j], color=color, markersize=10, label=f'{idx} dB')  #\n",
        "    j=j+2\n",
        "\n",
        "plt.xlim(0, 2000000)  # len(totalAttenData))\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Rain fade (dB)\")\n",
        "plt.grid(which='major')\n",
        "plt.show()\n",
        "\n",
        "elapsed_time = time.time() - start_time   #toc\n",
        "print(\"elapsedTime : {:9.9f} s\".format(elapsed_time))\n",
        "print('\\nFin!\\n')\n",
        "\n",
        "\n",
        "#%%\n",
        "def GRU_Stacked2(data):\n",
        "\n",
        "    # near perfect!\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    # import matplotlib.pyplot as plt\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "    # Load dataset\n",
        "    # data = pd.read_csv('/home/kdellubuntu/researchData/TestDataChilEdin.csv')\n",
        "    df = pd.DataFrame(data)   #, index=False, header=False)   # df = data\n",
        "\n",
        "    # Experiment with different window sizes\n",
        "    window_sizes = [5, 10, 15]\n",
        "\n",
        "    for window_size in window_sizes:\n",
        "        # Scaling the data with different scalers\n",
        "        scalers = [StandardScaler(), MinMaxScaler()]\n",
        "\n",
        "        for scaler in scalers:\n",
        "            # Prepare data for training\n",
        "            sequence_length = window_size\n",
        "            X, y = [], []\n",
        "\n",
        "            scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "            for i in range(len(scaled_data) - sequence_length):\n",
        "                X.append(scaled_data[i:i + sequence_length])\n",
        "                y.append(scaled_data[i + sequence_length])\n",
        "            X, y = np.array(X), np.array(y)\n",
        "\n",
        "            # Split data into training and testing sets\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "            # Model architecture\n",
        "            model = Sequential([\n",
        "                Bidirectional(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)),\n",
        "                Dropout(0.2),\n",
        "                GRU(64, return_sequences=False),\n",
        "                Dense(32, activation='relu'),\n",
        "                Dense(1)\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
        "\n",
        "            # Early Stopping and Learning Rate Scheduler\n",
        "            early_stopping = EarlyStopping(patience=15, restore_best_weights=True)\n",
        "            lr_scheduler = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "            # Make predictions\n",
        "            train_predictions = model.predict(X_train)\n",
        "            test_predictions = model.predict(X_test)\n",
        "\n",
        "            # Inverse transform predictions for visualization\n",
        "            train_predictions_inv = scaler.inverse_transform(train_predictions)\n",
        "            test_predictions_inv = scaler.inverse_transform(test_predictions)\n",
        "\n",
        "            # Calculate RMSE\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions_inv))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions_inv))\n",
        "\n",
        "            print(f\"Window Size: {window_size}, Scaler: {scaler.__class__.__name__}\")\n",
        "            print(f\"Train RMSE: {train_rmse:.4f}\")\n",
        "            print(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "            print(\"-----------------------\")\n",
        "\n",
        "    # # Visualization\n",
        "    # plt.figure(figsize=(12, 6))\n",
        "    # plt.plot(df.index[sequence_length:], df['Edin'][sequence_length:], label='Original Data')\n",
        "    # plt.plot(df.index[sequence_length:sequence_length + len(train_predictions_inv)], train_predictions_inv, label='Train Predictions', linestyle='dashed')\n",
        "    # plt.plot(df.index[sequence_length + len(train_predictions_inv):], test_predictions_inv, label='Test Predictions', linestyle='dashed')\n",
        "    # plt.xlabel('Time (secs)')\n",
        "    # plt.ylabel('Fade (dB)')\n",
        "    # plt.title('Time Series Prediction using Stacked GRU with Attention')\n",
        "    # plt.legend()\n",
        "    # plt.grid(which='major')\n",
        "    # plt.show()\n",
        "\n",
        "    return test_predictions_inv"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4JlOvTPppzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mz0UrjHFpN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2kSv7lSo70O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vlsgLcgvp-Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0iw7dSXsp-us"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}